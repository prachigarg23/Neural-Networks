{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a classifier for MNIST dataset using pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset (Dataset) – dataset from which to load the data.\n",
    "#batch_size (int, optional) – how many samples per batch to load (default: 1).\n",
    "#shuffle (bool, optional) – set to True to have the data reshuffled at every epoch (default: False).\n",
    "#num_workers (int, optional) – how many subprocesses to use for data loading. 0 means that the data will be loaded in the main process. (default: 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor()\n",
    "trainset = torchvision.datasets.MNIST(root='/tmp', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='/tmp', download=True, train=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=True, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 28, 28])\n",
      "7\n",
      "8\n",
      "4\n",
      "2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10cd8f390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualising data \n",
    "def show(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "print(images.size())\n",
    "show(torchvision.utils.make_grid(images))\n",
    "\n",
    "for j in range(4):\n",
    "    print(classes[labels[j]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARTIFICIAL NEURAL NETWORK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialMNIST(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SequentialMNIST, self).__init__()\n",
    "        self.linear1 = nn.Linear(28*28, 256)\n",
    "        self.linear2 = nn.Linear(256,10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear1(x.view(4, -1)))\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "net = SequentialMNIST()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "#defining loss function \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 0.00000\n",
      "[1,  4000] loss: 0.00003\n",
      "[1,  6000] loss: 0.00000\n",
      "[1,  8000] loss: 0.00000\n",
      "[1, 10000] loss: 0.00020\n",
      "[1, 12000] loss: 0.00000\n",
      "[1, 14000] loss: 0.00000\n",
      "[2,  2000] loss: 0.00000\n",
      "[2,  4000] loss: 0.00001\n",
      "[2,  6000] loss: 0.00001\n",
      "[2,  8000] loss: 0.00000\n",
      "[2, 10000] loss: 0.00000\n",
      "[2, 12000] loss: 0.00000\n",
      "[2, 14000] loss: 0.00001\n",
      "[3,  2000] loss: 0.00001\n",
      "[3,  4000] loss: 0.00000\n",
      "[3,  6000] loss: 0.00000\n",
      "[3,  8000] loss: 0.00000\n",
      "[3, 10000] loss: 0.00000\n",
      "[3, 12000] loss: 0.00000\n",
      "[3, 14000] loss: 0.00000\n",
      "[4,  2000] loss: 0.00000\n",
      "[4,  4000] loss: 0.00000\n",
      "[4,  6000] loss: 0.00000\n",
      "[4,  8000] loss: 0.00000\n",
      "[4, 10000] loss: 0.00000\n",
      "[4, 12000] loss: 0.00002\n",
      "[4, 14000] loss: 0.00000\n",
      "[5,  2000] loss: 0.00000\n",
      "[5,  4000] loss: 0.00000\n",
      "[5,  6000] loss: 0.00000\n",
      "[5,  8000] loss: 0.00003\n",
      "[5, 10000] loss: 0.00000\n",
      "[5, 12000] loss: 0.00000\n",
      "[5, 14000] loss: 0.00000\n",
      "[6,  2000] loss: 0.00000\n",
      "[6,  4000] loss: 0.00000\n",
      "[6,  6000] loss: 0.00000\n",
      "[6,  8000] loss: 0.00000\n",
      "[6, 10000] loss: 0.00000\n",
      "[6, 12000] loss: 0.00011\n",
      "[6, 14000] loss: 0.00000\n",
      "[7,  2000] loss: 0.00000\n",
      "[7,  4000] loss: 0.00000\n",
      "[7,  6000] loss: 0.00000\n",
      "[7,  8000] loss: 0.00000\n",
      "[7, 10000] loss: 0.00000\n",
      "[7, 12000] loss: 0.00000\n",
      "[7, 14000] loss: 0.00006\n",
      "[8,  2000] loss: 0.00000\n",
      "[8,  4000] loss: 0.00000\n",
      "[8,  6000] loss: 0.00000\n",
      "[8,  8000] loss: 0.00005\n",
      "[8, 10000] loss: 0.00000\n",
      "[8, 12000] loss: 0.00000\n",
      "[8, 14000] loss: 0.00001\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "for epoch in range(8):\n",
    "    running_loss=0.0\n",
    "    for i, data in enumerate(trainloader): ###\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad() ###\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        running_loss += loss.item()\n",
    "        if i%2000 == 1999:\n",
    "            print('[%d, %5d] loss: %.5f' % (epoch + 1, i + 1, running_loss / 2000))\n",
    "        running_loss = 0.0\n",
    "        \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of network on 10000 test images: 99 \n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        inputs , labels = data\n",
    "        outputs = net(inputs)\n",
    "        total += labels.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct += (predicted==labels).sum().item()\n",
    "print('accuracy of network on 10000 test images: %d ' % (100*correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONVNET ON MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvMNIST(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvMNIST, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16*4*4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = F.relu(self.fc1(x.view(-1, 16*4*4)))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "convnet = ConvMNIST()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 0.00117\n",
      "[1,  4000] loss: 0.00114\n",
      "[1,  6000] loss: 0.00115\n",
      "[1,  8000] loss: 0.00113\n",
      "[1, 10000] loss: 0.00115\n",
      "[1, 12000] loss: 0.00116\n",
      "[1, 14000] loss: 0.00115\n",
      "[2,  2000] loss: 0.00116\n",
      "[2,  4000] loss: 0.00114\n",
      "[2,  6000] loss: 0.00115\n",
      "[2,  8000] loss: 0.00115\n",
      "[2, 10000] loss: 0.00116\n",
      "[2, 12000] loss: 0.00117\n",
      "[2, 14000] loss: 0.00117\n",
      "[3,  2000] loss: 0.00116\n",
      "[3,  4000] loss: 0.00113\n",
      "[3,  6000] loss: 0.00116\n",
      "[3,  8000] loss: 0.00114\n",
      "[3, 10000] loss: 0.00117\n",
      "[3, 12000] loss: 0.00114\n",
      "[3, 14000] loss: 0.00114\n",
      "[4,  2000] loss: 0.00113\n",
      "[4,  4000] loss: 0.00114\n",
      "[4,  6000] loss: 0.00118\n",
      "[4,  8000] loss: 0.00117\n",
      "[4, 10000] loss: 0.00116\n",
      "[4, 12000] loss: 0.00114\n",
      "[4, 14000] loss: 0.00117\n",
      "[5,  2000] loss: 0.00115\n",
      "[5,  4000] loss: 0.00115\n",
      "[5,  6000] loss: 0.00117\n",
      "[5,  8000] loss: 0.00114\n",
      "[5, 10000] loss: 0.00115\n",
      "[5, 12000] loss: 0.00113\n",
      "[5, 14000] loss: 0.00114\n",
      "[6,  2000] loss: 0.00118\n",
      "[6,  4000] loss: 0.00113\n",
      "[6,  6000] loss: 0.00117\n",
      "[6,  8000] loss: 0.00119\n",
      "[6, 10000] loss: 0.00115\n",
      "[6, 12000] loss: 0.00116\n",
      "[6, 14000] loss: 0.00116\n",
      "[7,  2000] loss: 0.00117\n",
      "[7,  4000] loss: 0.00114\n",
      "[7,  6000] loss: 0.00118\n",
      "[7,  8000] loss: 0.00118\n",
      "[7, 10000] loss: 0.00116\n",
      "[7, 12000] loss: 0.00113\n",
      "[7, 14000] loss: 0.00115\n",
      "[8,  2000] loss: 0.00114\n",
      "[8,  4000] loss: 0.00117\n",
      "[8,  6000] loss: 0.00114\n",
      "[8,  8000] loss: 0.00116\n",
      "[8, 10000] loss: 0.00117\n",
      "[8, 12000] loss: 0.00117\n",
      "[8, 14000] loss: 0.00118\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "for epoch in range(8):\n",
    "    running_loss=0.0\n",
    "    for i, data in enumerate(trainloader): ###\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad() ###\n",
    "\n",
    "        outputs = convnet(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        running_loss += loss.item()\n",
    "        if i%2000 == 1999:\n",
    "            print('[%d, %5d] loss: %.5f' % (epoch + 1, i + 1, running_loss / 2000))\n",
    "        running_loss = 0.0\n",
    "        \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of network on 10000 test images: 9 \n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        inputs , labels = data\n",
    "        outputs = convnet(inputs)\n",
    "        total += labels.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct += (predicted==labels).sum().item()\n",
    "print('accuracy of network on 10000 test images: %d ' % (100*correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
